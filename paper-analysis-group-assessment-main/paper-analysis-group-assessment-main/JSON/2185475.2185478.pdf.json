{"TYPE": "document", "VALUE": [{"TYPE": "body", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Position paper: Towards a codelet-based runtime for exascale computing"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 576, "right": 432, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Christopher Lauderdale"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Rishi Khan "}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "ET International, Inc."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 3888, "right": 3744, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "{clauder,rishi}@etinternational.com"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}, {"TYPE": "table", "VALUE": [{"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "ABSTRACT"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 54, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "boost performance."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 94, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Processors can extract instruction-"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 126, "right": 0, "firstLine": 0}}}]}]}]}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Computing systems have reached the performance limits at-tainable by increasing clock rates and complexity, and are now using increased thread-level parallelism and heterogene-ity instead. "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "Existing software typically deals poorly with large-scale or heterogeneous computer systems, relying on multiple poorly interacting or special-purpose software in-terfaces to approach scaling/heterogeneity; attempting to use these approaches on future computers (especially at exa-scale) will only make matters worse."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 94, "right": 144, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "To solve this problem, software components may be bro-ken up into pieces, called\"codelets\", that can be dynamically scheduled without reliance on binding to any one thread or hardware component in relation to other codelets. By plac-ing a supporting runtime layer between the system interface and codelet-based application, a very high degree of par-allelism can be exposed, scaled, and scheduled to use the available hardware efficiently and intelligently. A codelet-based runtime can be used to create a clear path forward to exascale, as well as to deal with computing challenges in the interim."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 94, "right": 224, "firstLine": 170}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Categories and Subject Descriptors"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 94, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "level parallelism to help overcome this limitation [13], but this requires increased chip complexity, which increases power usage and reduces available chip space for other components. "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "Contemporary computers are thus coming to rely more heavily on thread-level parallelism, using a larger number of simpler, lower-power cores to replace fewer complex, higher-power ones. As core counts increase, small on-chip local memories, whether explicitly addressable or hardware-managed, have also become necessary to reduce the latency and power usage otherwise incurred by large numbers of cores accessing shared system memory. "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "To reach exascale, these local memories will need to be less coherent or under stricter software control than most caches in current use [16]."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 226, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "Heterogeneity is also increasingly common in computers, as architectures with differing capabilities and requirements (e.g., CPUs, GPUs/GPGPUs, and FPGAs) are mixed to-gether more freely. "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "Effectively utilizing and coordinating disparate components is a difficult matter, and typically in-volves use of special APIs for non-CPU components. Dealing with dynamic loads on these components that arise during parallel computation is also difficult, since work must typ-ically have been statically partitioned in order to use the"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 226, "right": 0, "firstLine": 0}}}, {"TYPE": "table", "VALUE": [{"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "D.1.3 [Concurrent Programming]:"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Parallel Program-"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 84, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "components in the first place."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 244, "right": 0, "firstLine": 0}}}]}]}, {"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "ming"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 54, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Unfortunately, contemporary software is generally ill-"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 412, "right": 0, "firstLine": 0}}}]}]}]}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "equipped to deal well with the hardware features of today's"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 22, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Keywords "}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "exascale, many-core, parallel, program execution model, dy-namic, adaptive, runtime, codelet"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 94, "right": 144, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "computers and even more poorly equipped to deal with exascale parallelism and memory structure, due in large part to reliance on traditional sequential processing and coherent memory models. Interfaces like OpenMP [7] can"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 226, "right": 22, "firstLine": 0}}}, {"TYPE": "table", "VALUE": [{"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "1."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 54, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "INTRODUCTION"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 68, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "ease a transition to multithreading, but software threads"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 1384, "right": 0, "firstLine": 0}}}]}]}, {"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "require enough memory, management overhead, and cen-"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 1384, "right": 0, "firstLine": 0}}}]}]}, {"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "tralization that they may not be practical in their present"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 1384, "right": 0, "firstLine": 0}}}]}]}, {"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "1.1"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Motivation"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 180, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": []}]}, {"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "form as larger-scale systems become prevalent."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 62, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Interfaces"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 74, "right": 0, "firstLine": 0}}}]}]}]}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Present-day computer systems have reached limits in the performance attainable using coarse-grained parallelism. Due to fundamental physical limitations, increased CPU clock rate is no longer the primary means by which to"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 94, "right": 224, "firstLine": 170}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "like MPI [11] and SHMEM [4] make it possible to coordinate explicit data transfer across a cluster, but make it difficult to deal well with the dynamic cross-cluster load presented by many programs, leading to under- or mis-utilization of com-puting resources. "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "Furthermore, inter-process/-node APIs like MPI interact poorly (or not at all) with multithreading interfaces, forcing threads, like nodes, to statically partition"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 226, "right": 0, "firstLine": 0}}}, {"TYPE": "table", "VALUE": [{"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 54, "right": 206, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "their workloads."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 244, "right": 0, "firstLine": 0}}}]}]}, {"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "1.2"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 96, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Proposed solution"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 130, "right": 0, "firstLine": 0}}}]}]}]}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 94, "right": 224, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "EXADAPT '12 March 3, 2012, London, UK."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 94, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Copyright 2012 ACM 978-1-4503-1147-2 ...$10.00."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 94, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "One of the problems underlying the above is that it can be difficult to expose enough parallelism in load-imbalanced programs to keep computing resources busy. "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "This stems partly from the overhead inherent in creating and switch-"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 226, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "21"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 4792, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "ing between threads; typically the operating system (OS) and/or several layers of system library must be involved, limiting the potential benefits of thread use in handling op-erations of unknown/unpredictable duration. In addition, neither the OS nor threading software can accurately ob-serve or react to the small-scale behavior of a long-running software thread without either imposing unacceptable over-"}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "Inter-head or undue hardship on software programmers."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 94, "right": 144, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "position of a software runtime layer between the OS and application allows the application to quickly and easily ex-pose parallelism and while the runtime manages scheduling and placement of application components [9]."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 94, "right": 224, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "An execution model that allows an application to describe finer-grained units of work will also be necessary, so that as much of an application as is ready to run can do so as soon as possible. Codelets, the fundamental unit of work considered in the model described by this paper, are small pieces of an application that can run to completion without blocking, and that explicitly suspend and resume execution if necessary to avoid running indefinitely."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 94, "right": 224, "firstLine": 170}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "One of the goals of a software runtime for exascale must be to minimize and hide long-latency memory accesses, which cause delays both from the accesses themselves and con-tention for bandwidth, and which increase power usage by engaging additional communications components. Codelets"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 94, "right": 224, "firstLine": 170}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "CT_Empty", "VALUE": "[w:drawing]"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 222, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Figure 1: An abstract machine model for a codelet"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 226, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "make it easier to coordinate access to distant and contentious "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "runtime."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 94, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "memory so that application components can trigger as re-"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 94, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "quired data become available, rather than stalling threads during a long-latency accesses. (This allows the runtime sys-tem to step in where hardware caches would be used on few-core systems.) Using the runtime layer for nonlocal memory access also makes it possible to transparently route object accesses into other address spaces without (e.g.) hardware-and latency-intensive virtual memory tricks, and makes it possible for the runtime to intelligently place codelet execu-tion based on the locations of input/output data."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 94, "right": 224, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "An additional component of the solution to the challenges arising from exascale computing is the use of locales, which give a high-level description of available hardware compo-nents and provide an interface whereby an application may schedule codelets to run, allocate memory, and exchange objects. Such an interface allows an application to specify precisely or generally where a codelet should run or where an object should reside in memory, when necessary."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 94, "right": 224, "firstLine": 170}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "sors, or other peripherals attached, all connected via a node-wide bus. "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "Each CPU chip or peripheral may have some amount of local addressable memory attached. A CPU chip contains one or more cores on it, each of which may time-multiplex its execution units amongst one or more hard-ware threads. Cores may be grouped into various levels of a communications hierarchy within the chip, and each core or group may have local memory associated with it. Cores within a group or CPU chip may be heterogeneous, as may a node's CPU chips. Figure 1 illustrates the relationships between hardware components in the machine model."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 226, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "For the purposes of this paper, more local memories are assumed to be smaller and have lower access latency than more remote memories. Caches and other non-addressable memories will not be considered, although they tend to fol-low the same pattern."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 226, "right": 36, "firstLine": 168}}}, {"TYPE": "table", "VALUE": [{"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "SWARM (SWift Adaptive Runtime Machine) is an exper-"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "2.2"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Abstract program model"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 30, "right": 0, "firstLine": 0}}}]}]}, {"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "imental codelet runtime that implements the ideas presented"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 54, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": []}]}, {"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "in this paper, with the aim of allowing applications to run"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 54, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "2.2.1"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 12, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Codelets"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 194, "right": 0, "firstLine": 0}}}]}]}, {"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "well on single-, few-, or many-core computers, as well as al-"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 54, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": []}]}]}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "lowing the application to transparently migrate across com-pute clusters or wider-area networks and between different kinds of computing hardware. This will allow applications to scale much more easily and widely, and makes a straight-forward software path to exascale possible."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 94, "right": 224, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "A codelet acts as the fundamental unit of scheduling and execution for a codelet runtime, and comprises the following:"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 226, "right": 0, "firstLine": 168}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "\u2022 A run fork, which describes work to be performed in "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "order to advance the state of the program."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 476, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "\u2022 An optional cancel fork, which describes how to back"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 476, "right": 0, "firstLine": 0}}}, {"TYPE": "table", "VALUE": [{"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "2."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 54, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "THE CODELET EXECUTION MODEL"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 68, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "out program state in case of an error."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 606, "right": 0, "firstLine": 0}}}]}]}, {"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "2.1"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Abstract machine model"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 180, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "\u2022 A description of the expected type of context frame (if"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 434, "right": 0, "firstLine": 0}}}]}]}, {"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "any) used to store the codelet's state information."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 606, "right": 0, "firstLine": 0}}}]}]}]}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "In this paper, an application is assumed to be running on one or more compute nodes in a compute cluster, all of which have separate memory address spaces and commu-nicate solely through a bus or network interconnect. Each node has one or more CPUs with some amount of DRAM"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 94, "right": 224, "firstLine": 170}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "\u2022 A description of the type of input data (if any) ex-"}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "pected by the codelet."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 476, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Codelets are represented within a codelet runtime as small descriptor objects referencing run/cancel fork functions and"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 226, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "shared amongst them and may have accelerators, coproces-"}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "context/input types."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 94, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "22"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 4808, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "CT_Empty", "VALUE": "[w:drawing]"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "The chain instance passed into a codelet complex is typ-ically used to effect communications with its initiator. A complex may chain by running or canceling the chain in-stance it was given at initiation. Running it (i.e., causing execution of its run fork) indicates successful completion of the complex's operation; canceling it (i.e., causing execu-tion of its cancel fork) indicates that the operation resulted in an error. By convention, any chain instance passed into a complex must be run or canceled exactly once before the complex's execution completes."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 222, "right": 40, "firstLine": 168}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Chaining has several important uses:"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 390, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "\u2022 Destruction of input/error parameters. Chaining pro-vides a means by which a complex's initiator can re-lease the memory associated with input/error data. (Chaining thus invalidates a complex's input/error pa-"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 644, "right": 42, "hanging": 172}}}, {"TYPE": "table", "VALUE": [{"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Figure 2:"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "State relationships and transitions of a"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 76, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "rameter.)"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 446, "right": 0, "firstLine": 0}}}]}]}]}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "codelet instance."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 94, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "By itself, a codelet is not ready to execute. A codelet instance may be created by associating a codelet with a context frame, and an enabled codelet instance addition-ally has associated input data for the run fork or error data for the cancel fork, as well as a chain instance which de-scribes further work to be started once the codelet's work"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 94, "right": 350, "firstLine": 170}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "\u2022 Return value passing. If a complex behaves like a sub-routine, it can use chaining to indicate completion of the subroutine and pass a return value to its initiator via the input parameter. If the initiator needs to pass such a return value directly out to its own initiator, it can effect tail-call-like behavior by passing a higher-level chain instance into the complex it initiates."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 522, "right": 42, "hanging": 172}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "\u2022 Bidirectional communication. Two complexes can en-ter into an arbitrarily long \"conversation\" by passing"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 522, "right": 0, "hanging": 172}}}, {"TYPE": "table", "VALUE": [{"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "completes."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "The chain instance may be used to provide a"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 82, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "secondary chain instances during chaining."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 446, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "This is"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 98, "right": 0, "firstLine": 0}}}]}]}]}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "communications path back to whatever started the codelet, and will be discussed in more detail in Sec. 2.2.2."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 94, "right": 144, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "A ready codelet instance is an enabled instance that has been registered with a scheduler so that it may be dis-patched and selected for execution, at which time the codelet instance will be considered active. An active codelet exe-cutes until completion, barring special runtime or operating system measures taken to preempt or block it, although the runtime may allow it to explicitly place itself in a suspended state and let other codelets run in its place. Figure 2 shows the states a codelet instance may attain and the additional data associated with each state."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 94, "right": 224, "firstLine": 170}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "When executing, a codelet should not block, engage in long-latency operations, or run indefinitely. A codelet has exclusive use of its hardware thread during execution, and without runtime-/OS-layer preemption, any other codelets are unable to use that thread until the codelet completes. To perform a long-latency or blocking operation, a codelet should start it asynchronously and register a codelet in-stance to be executed upon completion; "}, {"TYPE": "Break"}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "the operation may then be carried out in the background by other soft-ware/hardware layers while the codelet's thread is ceded to the runtime in the interim."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 94, "right": 144, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "merely an extension of subroutine-like behavior, and allows producer-consumer and coroutine-like seman-tics to be implemented within the same framework. This also enables unification of inter-node and inter-complex communications."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 648, "right": 42, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "\u2022 Extended error handling. If a faulting operation can be resumed, a secondary chain instance can be passed from a complex to its chain codelet's cancel fork; the secondary instance can be run or canceled to resume or abort the operation."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 648, "right": 42, "hanging": 172}}}, {"TYPE": "table", "VALUE": [{"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "2.2.3"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Interoperability between codelets and func-tions"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 114, "right": 0, "firstLine": 0}}}]}]}]}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "Most present-day architectures use a program stack for storage of activation records, and although use of codelets does not necessitate use of a stack, neither does it conflict with stack use. "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "For example, if run and cancel forks are implemented as functions, they can be called on the pro-gram stack by the runtime, and may in turn call other func-tions normally. The fork functions or their callees may also quickly suspend their execution and call back into the run-time scheduler, allowing other codelets' fork functions to run on the thread and use the remainder of the available stack"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 226, "right": 0, "firstLine": 0}}}, {"TYPE": "table", "VALUE": [{"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "2.2.2"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Codelet complexes and chaining"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 104, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "space. Platform-native exception handling may also be used, although a codelet runtime should catch exceptions escaping from run/cancel forks so that they don't propagate into the rest of the runtime."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 244, "right": 18, "firstLine": 0}}}]}]}, {"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "A codelet complex is an ad-hoc group of one or more codelets that work together to complete some task. These"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 54, "right": 144, "firstLine": 170}}}]}, {"TYPE": "table-cell", "VALUE": []}]}]}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "codelets will typically share a context, and may run sequen-tially or in parallel. To start a codelet complex, an initia-tor causes an entry codelet for the complex to be read-ied, passing the entry codelet appropriate context and input data, and optionally passing a chain instance referring back to the initiator's complex. If the complex involves multiple codelets, the entry codelet typically spills this information into a private context frame for later use; if the complex involves only one codelet, no private context is needed."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 94, "right": 224, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Section 2.2.2 noted that codelet complexes can be \"called\"much like subroutines; in addition, complexes can act as wrappers to integrate non-codelet-based functions into the codelet runtime, forwarding input data into a function as pa-rameters and its return value out as chain input. Conversely, functions can be used to wrap access to codelet complexes by starting an entry codelet and suspending until the initi-ated complex runs a chain instance. If the chain instance is run normally, its input can be passed back to the suspended"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 226, "right": 0, "firstLine": 168}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "23"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 4812, "firstLine": 0}}}, {"TYPE": "table", "VALUE": [{"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "codelet as a return value, and if canceled, the error can be passed back and thrown as a native exception."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 54, "right": 144, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "The need to wrap codelets in functions and vice versa can be avoided entirely if a compiler is able to generate codelets"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 54, "right": 144, "firstLine": 170}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "cially useful for distributed graph problems (e.g., Graph500, semantic web queries)."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 244, "right": 0, "firstLine": 0}}}]}]}, {"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "2.4"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 96, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Dealing with heterogeneity"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 130, "right": 0, "firstLine": 0}}}]}]}]}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "as its normal output. In this case, functions in program code can be transparently formulated as codelet complexes in the generated binary, enabling existing code to be recompiled in codelet form and adapted more easily to a codelet runtime. Because codelet dispatch typically has higher overhead than native stack-based function calls, a compiler may also refor-mulate codelet dispatches as native function calls."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 94, "right": 224, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "The above sections implicitly assumed that codelets have single forms of run or cancel forks that are executed when a codelet instance becomes active. However, if it is desired that a codelet be executable on disparate architectures or hardware components, multiple binary forms of the forks may be attached to the codelet's in-memory descriptor. In this case, the codelet runtime must select the appropriate"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 226, "right": 20, "firstLine": 168}}}, {"TYPE": "table", "VALUE": [{"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "2.3"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Locality awareness and management"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 120, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "binary form for the current hardware, or, if such a form"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 464, "right": 0, "firstLine": 0}}}]}]}, {"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "can't be found, the codelet must be relocated and executed"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 464, "right": 0, "firstLine": 0}}}]}]}]}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "All codelet execution occurs on a system component (typ-ically a hardware thread) managed by the codelet runtime. These components can be grouped together based on the degree of information which can readily be shared between them; for example, two threads that share a memory might be grouped together, or all cores on a node. These groupings can be nested into a tree-like structure, or locale tree, that describes the communication characteristics for software ex-ecuting on a distributed platform."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 94, "right": 226, "firstLine": 170}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Each locale in the tree has an associated allocator and scheduler, which respectively manage allocation of memory space and processing time within the locale. A leaf locale has no descendants, and its allocators and schedulers (or leaf allocators/schedulers) manage space/time allocation within their described hardware or software structures only. Higher-level locales, which do have descendants, may man-age their own allocation or their descendants'."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 94, "right": 226, "firstLine": 170}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "Because locales essentially represent bounded regions of a hardware/software platform, they provide an ideal interface for describing the transfer of data and control between those regions, including across boundaries for which ingress/egress communication normally requires special support (e.g., net-work interfaces). "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "Locales thus enable abstraction of dis-"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 94, "right": 144, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "on a compatible component."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 224, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Each leaf locale has an associated hardware component description associated with it, which describes the precise kind of device represented by the locale. Among other fea-tures, the component description includes information about instruction set architecture and available extensions. When different fork forms are present for a scheduled codelet, a scheduler can use its locale's component description to find an appropriate fork form to run. When a codelet is passed to a non-leaf scheduler, any descendant schedulers with com-patible architectures can potentially execute that codelet. Although codelets will likely have preferred architectures (a codelet that performs a matrix operation may run far faster on a GPU than on a CPU, for example) codelet-specified preferences will have to be weighed against resource avail-ability (the matrix operation can only run faster on a GPU if it can actually get time on that GPU). Different binary forms of the forks may also need to perform different actions, as appropriate for the architecture in question; for example, a fork compiled for a CPU may perform a smaller portion of a matrix operation than a GPU fork, may perform it in a different way, or may even schedule components of the operation on other nearby CPUs."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 224, "right": 20, "firstLine": 168}}}, {"TYPE": "table", "VALUE": [{"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "parate data transfer methods, including intra- and inter-"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 54, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "2.5"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 96, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Scheduling and allocation"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 130, "right": 0, "firstLine": 0}}}]}]}, {"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "node transfers."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 54, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": []}]}]}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "The locale hierarchy facilitates inter-locale control trans-fer as well as data transfer, allowing a group of codelets executing within one locale to easily widen, narrow, or en-tirely transplant their execution scope, simply by specifiyng a different target locale for scheduling. This allows a pro-gram component's execution to be explicitly or implicitly forwarded to data upon which it needs to act, and allows the system to dynamically react to data availability and place-ment. This differs from most existing runtimes' capabilities, which focus primarily on data movement and make it diffi-cult to cleanly migrate execution."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 94, "right": 224, "firstLine": 170}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "To enable codelets to easily control and inspect their po-sition within the locale hierarchy, every active codelet in-stance has an environment buffer associated with it that"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 94, "right": 224, "firstLine": 170}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Each locale in the hierarchy has an attached scheduler and allocator, which are used by an application to control runtime management of local time and memory. Schedulers accept enabled codelet instances and ready them for dis-patch, generally buffering readied instances in a queue or deque until a thread in the scheduler's locale is ready to run them; allocators accept requests for memory blocks and, when sufficient contiguous memory becomes available within their attached locale, readies codelets to run with the block address as their input."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 226, "right": 20, "firstLine": 168}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "The locale hierarchy can be used to establish delegating schedulers and allocators whose sole purpose is to select a descendant locale with available resources and forward re-quests into it. Schedulers and allocators for non-leaf locales"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 226, "right": 20, "firstLine": 168}}}, {"TYPE": "table", "VALUE": [{"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "describes the codelet's route and situation."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "The environ-"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 78, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "may also buffer requests and allow descendants to service"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 244, "right": 0, "firstLine": 0}}}]}]}]}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "ment buffer contains a reference to the first, most recent, current, next, and final locale for a codelet's execution and communication, and these can be changed during execution by a codelet to modify its own routing; for example, when effecting a return via a chain instance, a codelet can reverse the route before scheduling the chain instance. A codelet complex can also use the \"next locale\" field of the route in a for-all loop to distribute execution across a group of lo-cales, or can use the entire route to \"walk\" around the locale hierarchy collecting or updating local data, a practice espe-"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 94, "right": 224, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "them when the latter become idle or have sufficient free re-sources. Only leaf schedulers actually cause the execution of any codelets; non-leaf schedulers may forward or buffer scheduling requests, but do not handle them directly."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 226, "right": 20, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "A codelet runtime's leaf schedulers will likely need to sup-port a deque-based scheduling interface whereby a codelet can either be scheduled at the head of the deque, causing it to be dispatched immediately after the current codelet (a roughly LIFO ordering), or at the tail of the deque, caus-ing it to be dispatched after any other readied codelet in-"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 226, "right": 20, "firstLine": 168}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "24"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 4792, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "stances have been run (a roughly FIFO ordering). Sched-ulers might not cleave to the precise deque ordering, if other measures are taken (e.g.) to predictively optimize codelet ordering, but in general the deque ordering should be re-spected. FIFO ordering is typically sufficient and is often fairer to other application components, but some recursive problems encounter exponential blowup if strict FIFO or-dering is used (e.g., a recursive Fibonacci complex, which maxes out at about 1.6nscheduled codelets for input n), so the LIFO form of scheduling is often also useful."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 94, "right": 224, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "A simple leaf scheduler operates in a tight loop, repeatedly dequeueing codelets and dispatching them until it reaches an idle state or the runtime is shut down. Codelet schedul-ing may also be circumvented in some cases by calling the scheduled codelet's run/cancel fork immediately within the current stack, as long as there is enough remaining stack space; this avoids the overhead of enqueueing/pushing the codelet into the scheduler's deque structure and later de-queueing it, but implicitly suspends the original codelet to do so."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 94, "right": 224, "firstLine": 170}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "When a scheduler becomes idle, it may steal work from other schedulers around it in the hierarchy by consulting its parent locale's scheduler. If that scheduler has work to do, it can pass the work to the idle scheduler; otherwise, it can look for stealable work on the idle scheduler's siblings or consult its own parent scheduler. If no suitable work can be found, an idle scheduler can place its thread in a low-power state until work arrives. When an operating system layer exists beneath the runtime, an idle software thread may block to cede processor hardware to the OS; on bare-bones hardware, the runtime may be able to power- or clock-gate a core to save power."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 94, "right": 224, "firstLine": 170}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "Locales' allocators may act in a similar fashion to sched-ulers with respect to allocation requests. "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "For example, a leaf allocator, if unable to satisfy an allocation request, may push that request up to a higher level in the locale hierarchy; a non-leaf allocator may push the request upwards or down-wards. However, the cost of migrating allocation requests may outweigh the benefits; migration of a request gener-ally necessitates migration of the codelet execution resulting from request satisfaction, and that in turn may necessitate migration of a codelet's context and associated data."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 94, "right": 144, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "stances can be easily encapsulated and associated with data or control dependencies, then dispatched when those depen-dencies are satisfied, allowing program components to run as soon as possible instead of relying on global synchronization to break execution into distinct stages."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 226, "right": 20, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "4. "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "RELATED WORK"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 226, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "The basis for the concept of codelets comes from dataflow-related work by Gao et al., who implemented a prototype codelet-based execution model called EARTH [18], which ran on commodity hardware but suffered from scaling limi-tations. This codelet execution model has been extended to address the needs of exascale systems [20], although no im-plementing runtime exists. The execution model described in this paper discards some of the theoretical limitations imposed on codelets in Gao et al.'s model (e.g., prohibi-tion of codelet side-effects), adds cancellation semantics to simplify integration with programming language constructs such as exceptions, and adds chaining semantics to simplify establishment of dynamic dataflow interactions and memory cleanup."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 226, "right": 20, "firstLine": 168}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Other more commonly used frameworks for parallelizing and distributing programs have been in existence for some time, and include the following:"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 226, "right": 20, "firstLine": 168}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "\u2022 MPI [11], which aids distributed coordination/commu-nication within programs, but requires explicit trans-fers between address spaces and is primarily single-threaded."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 648, "right": 20, "hanging": 172}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "\u2022 SHMEM [4], an API that establishes a distributed co-ordination layer and store, but deals primarily with data exchange and remote synchronization and disre-gards threading."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 648, "right": 22, "hanging": 172}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "\u2022 OpenMP [7], a framework for integrating basic mul-tithreading control structures into existing program code, but which does not deal with multiple-address-space interactions and which primarily provides for fork/join-like programming patterns (esp. parallel for loops)."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 648, "right": 20, "hanging": 172}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "\u2022 Cilk [5], an extension to C for parallelizing recursion by using a fork-join paradigm on top of the existing threading model. Cilk deals well with recursive pro-"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 648, "right": 20, "hanging": 172}}}, {"TYPE": "table", "VALUE": [{"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "3."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "APPLICABILITY TO PARALLEL AL-"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 128, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "gramming patterns in a single address space, but does"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 526, "right": 0, "firstLine": 0}}}]}]}, {"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "not address other problems."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 526, "right": 0, "firstLine": 0}}}]}]}, {"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "GORITHM CLASSES"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 128, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "\u2022 TBB [15], an API that relies heavily on C++ tem-"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 354, "right": 0, "firstLine": 0}}}]}]}]}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "A codelet execution model and runtime are broadly ap-plicable to high-performance computing algorithms, which tend to fall into one of two rough classes: fork-join and dis-tributed dataflow. Fork-join algorithms include those based on recursion (e.g., game theory and decision analysis) and data-parallel or SIMD operations (e.g., partial differential equation solvers and Fast Fourier Transform). "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "Recursive algorithms can be parallelized well within a codelet run-time by judicious use of LIFO/FIFO codelet scheduling; data-parallel algorithms typically rely on parallel-for-like constructs, and can use locale hierarchy traversal to issue codelets to distinct schedulers."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 94, "right": 144, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Distributed dataflow algorithms include those that are primarily data-dependent, such as graph traversals (e.g., Graph500) or semantic web queries, and those that are pri-marily control-dependent, such as tiled linear algebra (e.g., PLASMA [2]) and adaptive mesh refinement. Codelet in-"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 94, "right": 224, "firstLine": 170}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "plates to parallelize programs and deals solely with thread interactions in a single process."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 648, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "\u2022 OpenCL [17], CUDA [14], and DirectCompute, which allow programmers to create program components that run on GPUs. These frameworks are specifically tai-lored to GPU-like accelerators, and deal only with the CPU-GPU interface."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 648, "right": 20, "hanging": 172}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Unfortunately, integrating more than one of these frame-works into a single application can be difficult, and due to disparate software interfaces for each component in the over-all system (nodes in a cluster, threads on a node, and ac-celerators on a node), programming and load-balancing in a way that effectively coordinates use of a cluster's resources can be difficult as well."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 226, "right": 20, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Other prior work includes ParalleX [12], which is a large-scale parallel runtime specification for which HPX [3] exists"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 226, "right": 0, "firstLine": 168}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "25"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 4792, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "as an implementation; the codelet runtime described in this paper is entirely compatible with ParalleX, and may be used as an underlying framework to implement its constructs."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 94, "right": 268, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "The locale hierarchy described in this paper is a close rel-ative of Hierarchical Place Trees (HPTs) used by the Ha-banero runtime [19], \"places\" in the X10 language [8], and locales in the Chapel language [6], as well as the Sequoia How-language's Parallel Memory Hierarchy (PMH) [10]."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 268, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "ever, Sequoia requires static partitioning within the PMH, X10 allows interaction only at leaf nodes of its place tree, and Chapel locales are not arranged in any hierarchy. Ha-banero's HPTs deal more with data locality and transfer than scheduling or processing, although they are otherwise largely the same as a codelet runtime's locales."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 94, "right": 268, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "[6] B. L. Chamberlain, D. Callahan, and H. P. Zima. Parallel programmability and the Chapel language. IJHPCA, 21(3):291-312, 2007."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 534, "right": 144, "hanging": 266}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "[7] B. Chapman, G. Jost, and R. van der Pas. Using OpenMP: Portable shared-memory parallel "}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "programming. The MIT Press, 2007."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 534, "right": 432, "hanging": 266}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "[8] P. Charles, C. Grothoff, V. Saraswat, C. Donawa, A. Kielstra, K. Ebcioglu, C. von Praun, and "}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "V. Sarkar. X10: An object-oriented approach to non-uniform cluster computing. In OOPSLA '05, pages 519-538, New York, NY, USA, 2005. ACM."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 534, "right": 288, "hanging": 266}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "[9] J. Dongarra, P. Beckman, T. Moore, et al. The International Exascale Software Project roadmap. IJHPCA, 25(1):3-60, 2011."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 534, "right": 288, "hanging": 266}}}, {"TYPE": "table", "VALUE": [{"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "5."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "ONGOING/FUTURE WORK"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 128, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "[10] K. Fatahalian, D. R. Horn, T. J. Knight, L. Leem,"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 844, "right": 0, "firstLine": 0}}}]}]}, {"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "M. Houston, J. Y. Park, M. Erez, M. Ren, A. Aiken,"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 1196, "right": 0, "firstLine": 0}}}]}]}]}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Although a full implementation of a codelet runtime as de-scribed in this paper is under active development, an earlier prototype version with a reduced scheduling interface and more limited codelet behavior already exists and is available for download from the ET International (ETI) web site [1]. SWARM is intended to present a complete runtime inter-face and toolkit that programmers or compilers can use to transparently distribute their applications across a compute node or cluster."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 94, "right": 224, "firstLine": 170}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "W. J. Dally, and P. Hanrahan. Sequoia: Programming the memory hierarchy. In Proceedings of the 2006 ACM/IEEE conference on Supercomputing, SC '06, New York, NY, USA, 2006. ACM."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 578, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "[11] W. Gropp, E. Lusk, and A. Skjellum. Using MPI. The "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "MIT Press, 2nd edition, Nov. 1999."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 226, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "[12] H. Kaiser, M. Brodowicz, and T. Sterling. ParalleX: An advanced parallel execution model for "}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "scaling-impaired applications. ICPPW, pages 394-401,"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 578, "right": 0, "hanging": 352}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Because generating codelets by hand and ensuring that "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "Sep. 2009."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 264, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "they interact correctly can be a daunting task for pro-"}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "[13] P. Machanick. Approaches to addressing the memory"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 94, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "grammers "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "accustomed "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "to "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "using "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "traditional "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "imperative "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "wall. Technical report, University of Brisbane,"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 94, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "languages, ETI is also developing a C-based language, SCALE (SWARM Codelet Association Language Exten-sions), to simplify asynchronous parallel programming. A prototype SCALE translator compatible with the aforemen-tioned SWARM prototype is available for download and has been used for in-house development on SWARM."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 94, "right": 224, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "6. "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "CONCLUSION"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 94, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "The codelet execution model, when combined with a ca-pable runtime, can allow software to be scalably parallelized much more easily and transparently than the thread-based and bulk-synchronous models in common use today. Such a runtime allows a clear path forward to exascale computing in the future, and can enable better utilization of hardware resources on present-day computers as well."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 94, "right": 224, "firstLine": 170}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "7. "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "REFERENCES"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 94, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "[1] SWARM beta download. Online at "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "http://etinternational.com/swarm."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 182, "right": 1440, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "[2] E. Agullo, J. Dongarra, B. Hadri, J. Kurzak, "}, {"TYPE": "Break"}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "J. Langou, H. Ltaief, P. Luszczek, and A. YarKhan."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 182, "right": 432, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "PLASMA users' guide. Technical report, ICL, University of Tennessee, Knoxville, TN, 2010."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 448, "right": 864, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "[3] M. Anderson, M. Brodowicz, H. Kaiser, and"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 182, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Brisbane, QLD, Australia, 2002."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 578, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "[14] NVIDIA Corporation, Santa Clara, CA. NVIDIA "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "CUDA programming guide, June 2007."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 226, "right": 288, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "[15] J. Reinders. Intel Threading Building Blocks. O'Reilly "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "Media, Sebastopol, CA, July 2007."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 226, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "[16] J. Shalf, S. Dosanjh, and J. Morrison. Exascale computing technology challenges. In VECPAR 2010, volume 6449 of Lecture Notes in Computer Science, pages 1-25. Springer Berlin / Heidelberg, 2011."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 578, "right": 144, "hanging": 352}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "[17] J. E. Stone, D. Gohara, and G. Shi. OpenCL: A parallel programming standard for heterogeneous computing systems. Computing in Science & Engineering, 12(3):66-72, May 2010."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 578, "right": 288, "hanging": 352}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "[18] K. B. Theobald. EARTH: An efficient architecture for running threads. PhD thesis, McGill University, "}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "Montreal, Que., Canada, 1999."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 578, "right": 0, "hanging": 352}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "[19] Y. Yan, J. Zhao, Y. Guo, and V. Sarkar. Hierarchical Place Trees: A portable abstraction for task "}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "parallelism and data movement. In Proceedings of the 22nd Workshop on Languages and Compilers for Parallel Computing, Oct. 2009."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 578, "right": 0, "hanging": 352}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "[20] S. Zuckerman, J. Suetterlein, R. Knauerhase, and G. R. Gao. Position paper: Using a \"codelet\" program execution model for exascale machines. In "}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "EXADAPT '11, New York, NY, USA, June 2011."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 578, "right": 0, "hanging": 352}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "T. Sterling. An application-driven analysis of the "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "CAPSL, ACM."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 448, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "ParalleX execution model. Technical report, Louisiana "}, {"TYPE": "Break"}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "State University, Baton Rouge, LA, USA, Sep. 2011. "}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "[4] R. Barriuso and A. Knies. SHMEM user's guide for C. "}, {"TYPE": "Break"}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "Cray Research, Inc., Eagan, MN, USA, June 1994."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 182, "right": 4896, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "[5] R. D. Blumofe, C. F. Joerg, B. C. Kuszmaul, C. E."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 182, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Leiserson, K. H. Randall, and Y. Zhou. Cilk: An "}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "efficient multithreaded runtime system. SIGPLAN "}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "Not., 30:207-216, August 1995."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 448, "right": 5184, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "26"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 4778, "firstLine": 0}}}]}]}
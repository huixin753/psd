{"TYPE": "document", "VALUE": [{"TYPE": "body", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "DiBB: Distributing Black-Box Optimization"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Giuseppe Cuccu "}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "Luca Rolshoven\u2217"}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "Fabien Vorpe\u2217"}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "Philippe Cudr\u00e9-Mauroux "}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "name.surname@unifr.ch "}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "Exascale Infolab "}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "University of Fribourg "}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "Switzerland"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 1296, "right": 1008, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "ABSTRACT"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 10, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "DiBB (for Distributing Black-Box) is a meta-algorithm and frame-work that addresses the decades-old scalability issue of Black-Box Optimization (BBO), including Evolutionary Computation. Algo-rithmically, it does so by creating out-of-the-box a Partially Sep-arable (PS) version of any existing black-box algorithm. This is done by leveraging expert knowledge about the task at hand to define blocks of parameters expected to have significant correla-tion, such as weights entering a same neuron/layer in a neuroevo-lution application. DiBB distributes the computation to a set of machines without further customization, while still retaining the advanced features of the underlying BBO algorithm, such as scale invariance and step-size adaptation, which are typically lost in recent distributed ES implementations. This is achieved by instan-tiating a separate instance of the underlying base algorithm for each block, running on a dedicated machine, with DiBB handling communication and constructing complete individuals for evalu-ation on the original task. DiBB's performance scales constantly with the number of parameter-blocks defined, which should allow for unprecedented applications on large clusters. Our reference implementation (Python, on GitHub and PyPI) demonstrates a 5x speed-up on COCO/BBOB using our new PS-CMA-ES. We also showcase a neuroevolution application (11 590 weights) on the PyBullet Walker2D with our new PS-LM-MA-ES."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 4, "right": 0, "firstLine": 6}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "CCS CONCEPTS"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 10, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "\u2022 Computing methodologies \u2192 Randomized search."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 10, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "KEYWORDS"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 10, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Black-Box Optimization, Distributed Algorithms, Parallelization, Evolution Strategies, Neuroevolution"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 10, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "\u2217This paper includes contributions from Rolshoven's and Vorpe's Master Thesis work."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 10, "right": 72, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "GECCO '22, July 9-13, 2022, Boston, MA, USA"}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "\u00a9 2022 Copyright held by the owner/author(s). Publication rights licensed to ACM."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 144, "firstLine": 10}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "ACM ISBN 978-1-4503-9237-2/22/07...$15.00"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 10, "right": 2304, "hanging": 4}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "341"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 44, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "GECCO '22, July 9-13, 2022, Boston, MA, USA "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "Cuccu, et al."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 6, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "(e.g. sep-CMA-ES [27] and SNES [29]), trading off significant con-vergence speed for wall-clock speed by relinquishing covariance information altogether [18]. Previous work by the authors also cov-ers a generalization of this trade-off by establishing a block-diagonal covariance matrix [6], leveraging the fact that the correlation among variables is not uniform for most complex problems, and that this information is often available to the user based on the target task. This provides initial inspiration for this work, as discussed below."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "1.1 "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "Intuition and design"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 6, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "BBO algorithms are designed to work in any unknowable (black-box) environment. By design, BBO algorithms cannot integrate task knowledge, in order to ensure that no illegitimate assumptions are made in their design. In most real-world applications however, some degree of expert knowledge is often available about the end task, making it rather a gray-box setting. Expert knowledge about the correlation between variables is often simple to deduce, as it is task-specific."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 6, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "For example in neuroevolution, where evolutionary algorithms learn the parameters of a neural network, weights of connections entering the same neuron are by necessity highly correlated, as the network's equation aggregates them in a linear combination prior to activation. While weights entering different neurons are not entirely uncorrelated, the expectation on their covariance is (relatively) significantly lower. A similar reasoning is easily made about neurons entering a same layer versus neurons in different layers, and remains true as the network expands towards deep networks1. The assumption of partial correlation, which allows partitioning the variables into highly intra-correlated blocks, leads to the blocks being separable between one another, i.e. low inter-correlation. The corresponding covariance matrix becomes block-diagonal, as explored in our previous work [6]."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 200}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "This paper extends the concept by leveraging the underlying assumption of separability between blocks to optimize each block of variables using a different, independent instance of the same BBO algorithm. As a consequence, block-wise computation can now be distributed across multiple machines: not only the individual fitnesses can be evaluated in an embarrassingly parallel fashion, but different blocks can be searched asynchronously, and each BBO instance can be distributed to different nodes in a cluster (see Figure 1)."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 6, "right": 56, "firstLine": 200}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Based on the above insights, this paper proposes a new meta-algorithm and framework for Distributed Black Box optimization, named DiBB. DiBB is particularly suited for large-scale problems evidently structured, as not infrequent (arguably common) in real-world applications. We provide rigorous theoretical arguments for the sample efficiency of this approach in Section 2, and further explore the example application of neuroevolution in Section 4.3."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 200}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "1.2 "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "Challenges"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 6, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "A major challenge comes with solution evaluation: a BBO instance running on one machine will produce a population of samples that are incomplete individuals, as the variables constituting a complete"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 6, "right": 76, "hanging": 6}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "1The fundamental assumption of partial separability across network layers however does not seem to be very well studied in the literature, despite a considerable body of work on neural network loss landscapes [10, 31]. This can be partially tracked to the limited availability of algorithms making use of partial correlation information."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 2, "right": 72, "hanging": 2}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "342"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 44, "right": 0, "firstLine": 0}}}, {"TYPE": "table", "VALUE": [{"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "DiBB: Distributing Black-Box Optimization"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "GECCO '22, July 9-13, 2022, Boston, MA, USA"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}]}]}, {"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Head node"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 308, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "BLOCK WORKER"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Worker node A"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "BLOCK WORKER"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 608, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Worker node B"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 292, "right": 0, "firstLine": 0}}}]}]}, {"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "DIBB"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 634, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "BBO instance"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 150, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Local copy of"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "BBO instance"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 158, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Local copy of "}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "global"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 144, "right": 2016, "firstLine": 0}}}]}]}, {"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": []}]}, {"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "MAIN ROUTINE"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 208, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "global"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": []}]}, {"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Local"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 368, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "reference solution:"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Local"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 366, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "reference solution:"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 88, "right": 0, "firstLine": 0}}}]}]}, {"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Object Store and"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 226, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "reference solution:"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 238, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "A B C D E F"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "table", "VALUE": [{"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": []}]}, {"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": []}]}]}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "objective function"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}, {"TYPE": "table", "VALUE": [{"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "FITNESS "}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "EVALUATOR"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 144, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Complex / expensive"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 86, "right": 288, "hanging": 12}}}]}, {"TYPE": "table-cell", "VALUE": []}]}, {"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": []}]}]}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "reference solution:"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 76, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "A B C D E F"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "table", "VALUE": [{"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": []}]}, {"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": []}]}]}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "objective function"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 372, "right": 0, "firstLine": 0}}}, {"TYPE": "table", "VALUE": [{"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "FITNESS "}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "EVALUATOR"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 144, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Complex / expensive"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 86, "right": 288, "hanging": 12}}}]}, {"TYPE": "table-cell", "VALUE": []}]}, {"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": []}]}]}]}]}, {"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Communication"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 246, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Complete solutions"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "E F"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 424, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Complete solutions"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": []}]}, {"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "C D"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 414, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": []}]}, {"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "array"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 676, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": []}]}, {"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Candidate samples:"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 214, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "ready for"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Candidate samples:"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 68, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "ready for"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": []}]}, {"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Global"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 614, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "evaluation:"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "evaluation:"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": []}]}, {"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "X X"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 380, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "A B X X E F"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "P T"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 390, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "A B C D P T"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": []}]}, {"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "reference solution:"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 180, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": []}]}, {"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Y Z"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 384, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "S P"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 398, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": []}]}, {"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "A B C D E F"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 324, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "A B Y Z E F"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "A B C D S P"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": []}]}, {"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Y Y"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 380, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "R T"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 382, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": []}]}, {"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "A B Y Y E F"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "A B C D R T"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": []}]}]}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Figure 1: Example architecture of DiBB as a framework. This is a sample instantiation on a cluster with 3 nodes: one acts as the head node, running the main routine, while two worker nodes encapsulate the underlying BBO and host the pools of Fitness Evaluators. This schema highlights how DiBB leverages Partial Separability in the construction of full samples ready for evaluation, and how the (potentially expensive) objective function is evaluated locally on the worker nodes."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 6, "right": 46, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "2 "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "A PRIMER ON EVOLUTION STRATEGIES"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 6, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "DiBB can be applied to any BBO algorithm to great and immediate advantage: even with methods that already treat the parameters as separable, DiBB provides a parallel and distributed implementation at the only cost of minimal overhead (for nontrivial applications). In this section however, we highlight modern Evolution Strategies as the state-of-the-art family of continuous black-box optimiza-tion methods, which we expect to gain the most from this new approach. The rationale here is that these methods have proven and popularized the importance of maintaining covariance infor-mation for search performance, and are thus best positioned to gain from DiBB's scalability into distributed computation. This choice however should not be interpreted as limited to neuroevolution applications, as DiBB users can adapt the partitioning of variables into blocks depending on each problem at hand."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 6, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "ES are direct search methods, which optimize a black-box objec-adaptive Gaussian distribution. We briefly review the types of ES tive function \ud835\udc53 : R\ud835\udc51\u2192 R by sampling candidate points from an most relevant for our discussion. The classic variant is the (1+1)-ES [26]. Its central algorithmic mechanism is step-size adaptation, i.e. its ability to actively adapt the standard deviation \ud835\udf0e > 0 of its Gaussian sampling distribution N (\ud835\udc5a, \ud835\udf0e2\ud835\udc3c) to the current needs. For the last 20 years, CMA-ES [18] has been the gold standard in ES research. Many variants exist, such as Natural Evolution Strategies (NES; Wierstra et al. 34). Its most important mechanism going be-yond \"simple\" step-size adaptive ES is covariance matrix adaptation (CMA), which means that not only the global step size \ud835\udf0e, but also the full covariance matrix \ud835\udc36 of the Gaussian N (\ud835\udc5a, \ud835\udf0e2\ud835\udc36) is adapted to the problem at hand."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 200}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "CMA-ES is a powerful optimizer; however, it was not designed for high-dimensional applications with hundreds of thousands of variables or more. Its internal parameters are not tuned with such a "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "2 regime in mind, and learning a full covariance matrix with\ud835\udc51 (\ud835\udc51+1) parameters is inherently slow. Such problems are commonly ad-dressed by placing specific restrictions on \ud835\udc36, such as being repre-sented by a diagonal matrix [27, 29], or a diagonal plus a low-rank matrix [1, 22, 23], or a block-diagonal matrix [6]. The number of parameters of the covariance matrix can hence be chosen flexibly"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 2, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "343"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 44, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "GECCO '22, July 9-13, 2022, Boston, MA, USA "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "Cuccu, et al."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 8, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "The OpenAI-ES [28], while being highly distributable, features neither step-size adaptation nor covariance adaptation. Based on the NES framework of Wierstra et al. [34], it leverages the ability of ES to estimate the natural gradient of \ud835\udc53 from samples, and then applies the ADAM optimizer on top. In effect, this is roughly comparable to using a diagonal \ud835\udc36."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 8, "right": 76, "firstLine": 200}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "CMA has a price in terms of algorithm internal complexity, and in addition the adaptation process is slow even in terms of sample complexity-due to large hidden constants in its performance es-timation. The above convergence rates measure time in terms of the number of objective function evaluations (sample complexity). When scaling up CMA to high dimensions however, we need to take the following concepts into consideration. Algorithm internal complexity refers to the required (amortized) number of operations needed for creating a sample and for updating the internal state-the covariance matrix in particular. This concept will be re-explored later when introducing distributed computing, as DiBB employs multiple machines to evaluate proportionally more samples without impacting wall-clock time. For now, regarding sample complexity, we distinguish between the number of samples needed to learn the covariance matrix, and the number of samples needed to solve the problem."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 200}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "For example, a (small) neural network with \ud835\udc51 = 104weights results Learning \ud835\udc36 with up to \u0398(\ud835\udc512) parameters is sample-inefficient."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "in\ud835\udc51 (\ud835\udc51+1) these takes hundreds of millions of samples, each of which can be "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "2"}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "\u2248 5 \u00b7 107parameters of the covariance matrix. Learning"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 8, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "significantly expensive: imagine for example a continuous control task involving a robot interacting in a physics simulation. This quickly becomes far too slow for practical use, even without taking into consideration the (typically expensive) covariance update step in the underlying algorithm. For larger \ud835\udc51, even the storage of the full covariance matrix \ud835\udc36 quickly becomes prohibitive. Furthermore, performing computations with \ud835\udc36 scales at least linear with the number of its parameters, which amounts to an internal complexity of \u03a9(\ud835\udc512) for full CMA. Since network evaluation scales linearly with the number of weights\ud835\udc51 (in a direct encoding scheme), CMA quickly becomes the computational bottleneck. Therefore, a different trade-off between fast convergence and internal complexity is needed, which can be realized for example with block-diagonal and low-rank structures, and combinations thereof. Or, in the case of the proposed work, by leveraging the partial correlation assumption to construct a block-diagonal covariance matrix."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 2, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "2.3 "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "Implications for Neural Network Training"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 8, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Diagonal, block-diagonal, and low-rank schemes successfully lower both internal and sample costs of CMA significantly (at the expense of higher sample complexity for solving the overall problem). There-fore, they are key to the application of modern ES based on CMA to real-world problems, especially involving expensive physics sim-ulations as common in reinforcement learning applications."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 8, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "In neural network training, weight spaces are often extremely high-dimensional. However, they also come with a canonical struc-ture, induced by the network topology. Hence, a block-diagonal covariance structure with one block per layer (or per neuron) is a natural choice. It should be noted that there exist approaches for identifying a problem decomposition automatically [24], if needed,"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 8, "right": 0, "firstLine": 200}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "344"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 44, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "DiBB: Distributing Black-Box Optimization"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 10, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "The BW encapsulates the actual BBO algorithm, and runs fully asynchronously from the others, though contemporary."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 432, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "The BWs exchange information by uploading to the head node the state of their search after each update (i.e. a gen-eration in ES); updates from the other nodes are also pulled before generating a new population."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 498, "right": 58, "hanging": 6}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "(4) In our implementation, each BW can spawn a pool of Fitness Evaluators (FE) on the same machine, used to automatically manage limited computational resources (such as available CPUs)."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 498, "right": 70, "hanging": 270}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "(5) Alternatively, the user can request to evaluate trivial opti-mization functions on the BW directly (either sequentially or using multithreading), which is useful when the over-head of maintaining a discrete pool of evaluators would be significant with respect to the cost of the actual evaluation task."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 498, "right": 0, "hanging": 270}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "The Block Workers communicate with the head node in each generation, while generation cycles are defined asynchronously and autonomously by each BW. Consider a problem with \ud835\udc51 variables \ud835\udc651, . . . ,\ud835\udc65\ud835\udc51, and a BW optimizing \ud835\udc4f variables \ud835\udc65\ud835\udc4e, . . . ,\ud835\udc65\ud835\udc4e+\ud835\udc4f\u22121, denoted as the vector \ud835\udc65\ud835\udc35 for short. The head node maintains a reference solution \u00af\ud835\udc65 \u2208 R\ud835\udc51, which fulfills a two-fold purpose: it serves as an anytime-estimate of the state of the search (current optimum), and it provides a unifying context to the BWs and the FEs."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 4, "right": 76, "firstLine": 200}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "Intuitively, each BW is only aware of the variables in one block, and can only generate samples for the corresponding variables. These incomplete samples however need to be constructed as part of a complete solution in order to be scored on the task. In our recurring example of neuroevolution, the sample could correspond to the weights for a neuron, or layer, while obviously only full networks can be evaluated on the task. We address this issue by leveraging once again our assumption of partial separability. After our hypothesis of the correlation across blocks being negligible, we can evaluate each block in isolation by inserting it in the context of the (current) reference solution, as obtained from the head node. "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "Hypothesize for a moment that there is no correlation inter-block-we will address the validity of this statement just below. In this case, each layer can be scored fairly by constructing a full reference network, then swapping the corresponding weights in the target layer for the block sample, and finally evaluating the resulting complete network on the task. Different independent sam-ples from a same block (individuals) would receive fair evaluation in this fashion as long as they are evaluated on the same refer-ence network. This is in fact constructed by assembling the partial sample into the global reference solutions. Partial samples are con-structed by aggregating the reference or center sample from each of the BBO instances running on each block, which as mentioned is maintained in the head node by each block instance at the end of each generation."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 4, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "More formally: at the start of each generation, the BW receives the current reference solution \u00af\ud835\udc651, . . . , \u00af\ud835\udc65\ud835\udc51 from the head node.2 The block-level ES samples a population of candidate solutions \ud835\udc661, . . .\ud835\udc66\ud835\udf06\u2208 R\ud835\udc4f. If \ud835\udc4f is small, then sampling from a Gaussian with full covariance matrix N (\ud835\udc5a, \ud835\udf0e2\ud835\udc36) is feasible. The \ud835\udc4f-dimensional"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 76, "firstLine": 200}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "2It would suffice to send \u00af\ud835\udc651, . . . , \u00af\ud835\udc65\ud835\udc4e\u22121, \u00af\ud835\udc65\ud835\udc4e+\ud835\udc4f, . . . , \u00af\ud835\udc65\ud835\udc51 to the BW, but the difference has been negligible in our experiments so far up to 30 blocks."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "345"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 44, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "GECCO '22, July 9-13, 2022, Boston, MA, USA "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "Cuccu, et al."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 8, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "The problem is smartly sidestepped by Salimans et al. [28] by synchronizing the entropy (random number generation) across the machines, which makes them generate the same samples, however at the price of a fully-synchronous implementation (and greatly sim-plified algorithm). The same method can be implemented into DiBB to allow a Block Worker to spawn Fitness Evaluators across multiple machines, which would immediately improve performance partic-ularly in the case of large population sizes. With DiBB however, the actual updates would remain asynchronous, which implies that the FEs spawned in the cluster could actually be shared between BWs. Since this communication overhead occurs only once per (block-wise) generation in DiBB, and not once per fitness evalua-tion, our implementation has considerable less pronounced network overhead than in the distribution of fitness evaluation in a plain ES."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 2, "right": 0, "firstLine": 200}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "4 "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "EXPERIMENTS"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 8, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "This section describes the setup used to empirically assess the performance of DiBB. With our experiments, we aim to address the following research questions: "}, {"TYPE": "Break"}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "Q1: How well does the block-diagonal approach work, compared "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "to diagonal- and full-covariance CMA?"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 2, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Q2: How does DiBB's performance scale to a large number of "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "machines and cores?"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 164, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Q3: Is DiBB well-suited for neuroevolution applications?"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 164, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "We assess the first two questions on the standard COmparing Con-tinuous Optimizers (COCO) Black Box Optimization Benchmark (BBOB), using both the standard [17] and the large-scale [9] bench-mark suites. For answering the third question, we showcase a neu-roevolution application in the challenging OpenAI Gym 2D Walker environment."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 8, "right": 0, "hanging": 8}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "4.1 "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "Setup and reference implementation"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 8, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "We tested DiBB on a variety of hardware solutions. The COCO-BBOB experiments were run on a cluster of 24 low-performance machines, all based on an Intel(R)Core(TM)i7-2600 CPU @ 3.40GHz (4 cores/8 threads each), and 32 GB of RAM. These machines are far from state-of-the-art performance, which leaves a significant margin of improvement for the timings presented in our results. This decision was taken to encourage interested labs to reproduce our results on whatever hardware they can put together, without expectation of dedicating any significant budget."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 8, "right": 0, "hanging": 8}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "The cluster setup is simplified by the included managing scripts. Running on a single machine with a single block and no Fitness Evaluators roughly corresponds to running the underlying BBO algorithm alone (plus overhead, and with parallel fitness evaluation), and can be achieved without setup with a syntax alike to CMA-ES. Spawning multiple BWs and FEs automatically scales to the available resources, as declared in the managing script using a simple list of network IPs."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 8, "right": 0, "firstLine": 200}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "The experiments below are based on our reference implementa-tion of DiBB written in Python, which leverages the Ray distributed computation library3. The code is released open source on GitHub"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 8, "right": 0, "firstLine": 200}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "3- a Python framework for distributed computing"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 8, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "346"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 44, "right": 0, "firstLine": 0}}}, {"TYPE": "table", "VALUE": [{"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "DiBB: Distributing Black-Box Optimization"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "CT_Empty", "VALUE": "[w:drawing]"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "GECCO '22, July 9-13, 2022, Boston, MA, USA"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 16, "firstLine": 0}}}]}]}, {"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "CT_Empty", "VALUE": "[w:drawing]"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": []}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "CT_Empty", "VALUE": "[w:drawing]"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "CT_Empty", "VALUE": "[w:drawing]"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}]}]}]}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Figure 2: ECDF plots of the performance of PS-CMA-ES, sep-CMA-ES and standard CMA-ES in dimension 320. From left to right: f1-f5 with Exp. 1/Exp. 3, Exp. 2/Exp. 4, then f10-f14 with Exp. 1/Exp. 3, Exp. 2/Exp. 4. The curves show the fraction of precision targets reached over time, measured as number of function evaluations divided by problem dimension, on a logarithmic scale. For additional information on ECDF plots, please refer to [16]."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 6, "right": 50, "firstLine": 0}}}, {"TYPE": "table", "VALUE": [{"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Number of"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 152, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Number"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Block"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Duration"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 110, "right": 0, "firstLine": 0}}}]}]}, {"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "dimensions"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 92, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "of blocks"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "size"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 104, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": []}]}, {"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "40 "}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "80 "}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "160 "}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "320 "}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "640"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 864, "right": 432, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "1 "}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "2 "}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "4 "}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "8 "}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "16"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 288, "right": 288, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "40 "}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "40 "}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "40 "}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "40 "}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "40"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 254, "right": 240, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "25h 13m 47s 43h 26m 57s 40h 21m 01s 44h 53m 29s 61h 20m 11s"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 110, "right": 572, "firstLine": 0}}}]}]}, {"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Table 2: Timing results for Experiment 4: BBOB large-scale suite with fixed block size (5\u00d7 budget). Larger problem di-mensions are addressed here with increasing the number of blocks. Since each block is optimized in parallel, the increase in run time of the experiments is only limited to communi-cation overhead, thus small as problem dimensions grow."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 6, "right": 0, "hanging": 6}}}]}]}]}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "process by providing publicly available performance data for many state-of-the-art algorithms.7 "}, {"TYPE": "Break"}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "We test the scaling of DiBB's performance as we vary in turn the problem dimensions and the block size, from the related but radi-cally different perspectives of sample efficiency (i.e. convergence speed, how many samples it takes for the algorithm to reach con-vergence) and effective run time (i.e. wall-clock speed, how long it actually takes for the algorithm to converge in real time). In the case of DiBB, run time is significantly (positively) impacted by its inher-ent distributed implementation, as each BW evaluates the fitness of its individuals locally in its dedicated machine, asynchronously from all other BWs."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 2, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "To this end, we ran the following experiments: "}, {"TYPE": "Break"}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "(1) Constant number of blocks, increasing \ud835\udc51 and block size, on "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "the BBOB suite (bbob_fnb) "}, {"TYPE": "Break"}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "(2) Constant block size, increasing \ud835\udc51 and number of blocks on "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "the BBOB suite (bbob_fbs) "}, {"TYPE": "Break"}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "(3) Constant number of blocks, increasing \ud835\udc51 and block size on "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "the large-scale suite (bbob_ls_fnb) "}, {"TYPE": "Break"}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "(4) Constant block size, increasing \ud835\udc51 and number of blocks on "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "the large-scale suite (bbob_ls_fbs) "}, {"TYPE": "Break"}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "(5) Comparison of the wall-clock speed between plain CMA-ES "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "and PS-CMA-ES using different block sizes "}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "Complete details of the experimental setup for reproducibility pur-pose are found in Appendix A.1."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 6, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "7See"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 4, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "347"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 34, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "GECCO '22, July 9-13, 2022, Boston, MA, USA "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "Cuccu, et al."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 8, "right": 0, "firstLine": 0}}}, {"TYPE": "table", "VALUE": [{"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Blocks"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Duration"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 118, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Relative Time"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Speed Gain"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 112, "right": 0, "firstLine": 0}}}]}]}, {"TYPE": "table-row", "VALUE": [{"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "1 "}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "2 "}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "4 "}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "8 "}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "16"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 8, "right": 458, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "17h 43m 41s 17h 33m 30s 06h 32m 19s 03h 56m 56s 03h 06m 05s"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 118, "right": 84, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "100.00% "}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "99.04% "}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "36.88% "}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "22.27% "}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "17.49%"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 116, "right": 576, "firstLine": 0}}}]}, {"TYPE": "table-cell", "VALUE": [{"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "0.00% "}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "0.97% "}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "171.13% 348.94% 471.62%"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 112, "right": 288, "firstLine": 0}}}]}]}]}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Table 3: Timing results for Experiment 5: BBOB large-scale suite in 160 dimensions using different block sizes. The first row (one block) corresponds to running CMA-ES without DiBB. When using only two blocks, we observe almost the same wall-clock time. For larger number of blocks however, the time is significantly reduced."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 8, "right": 0, "hanging": 6}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "40d BBOB large-scale suite with one block (another single-machine run)."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 8, "right": 0, "hanging": 4}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Tables 1 and 2 compare the run times of DiBB with different numbers of blocks, block sizes, and dimensions on the BBOB large-scale suite. Several effects come together: in larger dimensions, function evaluation time and communication overhead grow lin-early. Due to the fixed budget multiplier used in COCO, the overall function evaluation budget also grows linearly. On the other hand, CMA's computational effort grows quadratically in the block size. We clearly observe that the runtime grows far more benign when using a fixed block size, which indicates that CMA overhead indeed quickly becomes the dominating term. Hence, the block size should be kept tightly under control. This answers question Q2. Addition-ally, Table 3 compares the wall-clock speed of PS-CMA-ES using different block sizes on the 160d BBOB large-scale problems suite. For one vs. two blocks, there is almost no difference in the duration of the experiment. However, for four or more blocks, the wall-clock time diminished drastically, leading to a speed gain of 471%. Note that for BBOB and most other benchmark problems, evaluations are unrealistically cheap, so DiBB's parallelization overhead becomes relatively significant. For a more realistic function evaluation cost (i.e. as little as 10ms) the overhead becomes negligible, highlighting the benefit of parallel evaluations."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 200}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "4.3 "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "PyBullet Walker 2D"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 8, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Although DiBB can be applied to any existing BBO and problem, its value in neuroevolution applications has undeniably been one of the original inspirations, particularly in relation to neural net-works of large size. Therefore we present our results on a complex reinforcement learning control task: the Walker 2D environment from PyBullet [5], instantiated through the OpenAI Gym [3]."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 8, "right": 0, "hanging": 6}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "In this task, an agent controls a basic 2D robotic walker using the PyBullet physics simulator. The observation is a 22-dimensional reading of the environment (e.g. aperture and angular velocity of each joint, etc.), while the action is a 6-dimensional torque-control signal. The goal of the task is for the robot to walk the farthest distance possible in the allotted time, without toppling, which in turn requires learning a usable gait."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 8, "right": 76, "firstLine": 200}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "The policy network is feed-forward and fully connected, com-posed by two hidden layers of sizes [128, 64], using ReLU activa-tions. The output layer is composed of six neurons with rescaled tanh activation normalized to the range of motor commands."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 8, "right": 0, "firstLine": 200}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "348"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 44, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "DiBB: Distributing Black-Box Optimization"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "REFERENCES "}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "[1] Youhei Akimoto, Anne Auger, and Nikolaus Hansen. 2014. Comparison-based "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "natural gradient optimization in high dimension. In Genetic and Evolutionary "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "Computation Conference. ACM, 373-380."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "[2] Charles Audet and Warren Hare. 2017. Derivative-free and blackbox optimization. "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "Springer."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 64, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "[3] Greg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "OpenAI Gym. Schulman, Jie Tang, and Wojciech Zaremba. 2016."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 64, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "arXiv"}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "[4] Patrya Loshchilov, and Frank Hutter. 2018. Back to basics: "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "Benchmarking Canonical Evolution Strategies for Playing ATARI. Technical Report "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "1802.08842. arXiv.org."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 64, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "[5] Erwin Coumans and Yunfei Bai. 2016-2021. PyBullet, a Python module for physics "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "simulation for games, robotics and machine learning."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 64, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "[6] Giuseppe Cuccu and Faustino Gomez. 2012. Block dilution strategies. In International Conference on Parallel Problem Solving from Nature. Springer, 488-497."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 308, "right": 0, "hanging": 244}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "[7] Giuseppe Cuccu, Julian Togelius, and Philippe Cudr\u00e9-Mauroux. 2019. Playing "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "Atari with six neurons. In Proceedings of the 18th International Conference on "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "Autonomous Agents and MultiAgent Systems. International Foundation for Au-"}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "tonomous Agents and Multiagent Systems, 998-1006. "}, {"TYPE": "TabChar"}, {"TYPE": "TabChar"}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "[8] wat. 2008. MapReduce: simplified data processing "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "on large clusters. Commun. ACM 51, 1 (2008), 107-113. "}, {"TYPE": "TabChar"}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "[9] ara, Konstantinos Varelas, Duc Manh Nguyen, Tea Tu\u0161ar, Dimo "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "Brockhoff, Nikolaus Hansen, and Anne Auger. 2019. COCO: The Large Scale "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "Black-Box Optimization Benchmarking (bbob-largescale) Test Suite. "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "arXiv "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "preprint arXiv:1903.06396 (2019)."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 64, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "[10] Stanislav Fort and Stanislaw Jastrzebski. 2019. Large scale structure of neural network loss landscapes. Advances in Neural Information Processing Systems 32 (2019), 6709-6717."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 308, "right": 72, "hanging": 308}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "[11] Herv\u00e9 Fournier and Olivier Teytaud. 2011. Lower bounds for comparison based evolution strategies using vc-dimension and sign patterns. Algorithmica 59, 3 (2011), 387-408."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 308, "right": 72, "hanging": 308}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "[12] David Ha and J\u00fcrgen Schmidhuber. 2018. Recurrent world models facilitate policy "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "evolution. Technical Report 1809.01999. arXiv.org."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "[13] Nikolaus Hansen. 1996. Adapting Arbitrary Normal Mutation Distributions in Evolution Strategies: The Covariance Matrix Adaptation. In IEEE International Conference on Evolutionary Computation, 1996. 312-317."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 308, "right": 70, "hanging": 308}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "[14] Nikolaus Hansen. 2019. A global surrogate assisted CMA-ES. In Proceedings of the "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "Genetic and Evolutionary Computation Conference. ACM, Prague Czech Republic, "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "664-672. "}, {"TYPE": "Break"}, {"TYPE": "text", "VALUE": "[15] Nikolaus H2015. Evolution strategies. In "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "Springer handbook of computational intelligence. Springer, 871-898."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "[16] Nikolaus Hansen, Anne Auger, Raymond Ros, Steffen Finck, and Petr Po\u0161\u00edk."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "2010. Comparing results of 31 algorithms from the black-box optimization benchmarking BBOB-2009. In Proceedings of the 12th annual conference companion on Genetic and evolutionary computation. 1689-1696."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 308, "right": 70, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "[17] Nikolaus Hansen, Steffen Finck, Raymond Ros, and Anne Auger. 2009. Real-"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "Parameter Black-Box Optimization Benchmarking 2009: Noiseless Functions Defini-tions. Technical Report RR-6869. INRIA."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 308, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "[18] Nikolaus Hansen and Andreas Ostermeier. 2001. Completely Derandomized Self-Adaptation in Evolution Strategies. Evolutionary Computation 9, 2 (2001), 159-195."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 308, "right": 56, "hanging": 308}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "[19] Verena Heidrich-Meisner and Christian Igel. 2009. Neuroevolution strategies for "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "episodic reinforcement learning. Journal of Algorithms 64, 4 (2009), 152-168. [20] Christian Igel. 2003. Neuroevolution for Reinforcement Learning using Evolution "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "Strategies. In The 2003 Congress on Evolutionary Computation (CEC'03), Vol. 4. "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "IEEE, 2588-2595."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "[21] Jens J\u00e4gersk\u00fcpper. 2006. How the (1+1)-ES using isotropic mutations minimizes positive definite quadratic forms. Theoretical Computer Science 361, 1 (2006), 38-56."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 308, "right": 56, "hanging": 308}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "[22] Ilya Loshchilov. 2014. A Computationally Efficient Limited Memory CMA-ES for Large Scale Optimization. In Genetic and Evolutionary Computation Conference. ACM, 397-404."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 308, "right": 50, "hanging": 308}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "[23] Ilya Loshchilov, Tobias Glasmachers, and Hans-Georg Beyer. 2018. Large Scale Black-box Optimization by Limited-Memory Matrix Adaptation. IEEE Transac-tions on Evolutionary Computation 99 (2018)."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 308, "right": 58, "hanging": 308}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "[24] Mohammad Nabi Omidvar, Xiaodong Li, Yi Mei, and Xin Yao. 2013. Coopera-tive co-evolution with differential grouping for large scale optimization. IEEE Transactions on Evolutionary Computation 18, 3 (2013), 378-393."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 308, "right": 0, "hanging": 308}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "[25] Matthias Plappert, Rein Houthooft, Prafulla Dhariwal, Szymon Sidor, Richard Y Chen, Xi Chen, Tamim Asfour, Pieter Abbeel, and Marcin Andrychowicz. 2017."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 308, "right": 0, "hanging": 308}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "Parameter space noise for exploration. Technical Report 1706.01905. arXiv.org. [26] Ingo Rechenberg. 1973. Evolutionsstrategie: Optimierung technischer Systeme nach "}, {"TYPE": "TabChar"}, {"TYPE": "text", "VALUE": "Prinzipien der biologischen Evolution. Frommann-Holzboog."}], "style": {"indent": {"TYPE": "CT_Ind", "left": 0, "right": 0, "firstLine": 0}}}, {"TYPE": "paragraph", "VALUE": [{"TYPE": "text", "VALUE": "349"}], "style": {"indent": {"TYPE": "CT_Ind", "left": 48, "right": 0, "firstLine": 0}}}]}]}